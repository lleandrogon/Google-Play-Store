# Projeto de Pipeline no Databricks

Este reposit√≥rio cont√©m o c√≥digo e a estrutura de um pipeline de dados desenvolvido para rodar **exclusivamente no Databricks**, utilizando **PySpark**, **Delta Lake** e **Jobs do Databricks** para orquestra√ß√£o e valida√ß√µes entre as camadas do lake.

## üöÄ Vis√£o Geral do Projeto

O objetivo deste projeto √© processar e transformar dados brutos provenientes da base "Google Play Store", realizando a evolu√ß√£o das camadas:

* **Bronze** ‚Üí ingest√£o dos dados brutos
* **Silver** ‚Üí limpeza, padroniza√ß√£o e valida√ß√µes
* **Gold** ‚Üí agrega√ß√µes e tabelas finais para consumo

Todo o fluxo √© executado dentro do Databricks e **n√£o roda localmente**.

---

## üß± Arquitetura do Pipeline

O pipeline segue a abordagem de medallion architecture:

### **1. Bronze**

* Ingest√£o direta dos arquivos originais
* Armazenamento em formato Delta
* Sem transforma√ß√µes complexas

### **2. Silver**

* Padroniza√ß√£o dos tipos de dados
* Remo√ß√£o e tratamento de inconsist√™ncias
* Regras de qualidade de dados
* Escrita em Delta

### **3. Gold**

* M√©tricas, agrega√ß√µes e indicadores finais
* Tabelas otimizadas para an√°lise

---

## üîß Tecnologias Utilizadas

* **Databricks (Community ou Enterprise)**
* **PySpark**
* **Spark SQL**
* **Delta Lake**
* **Databricks Jobs** (para orquestra√ß√£o)
* **Databricks Notebooks**

---

## üß≠ Orquestra√ß√£o com Databricks Jobs

A orquestra√ß√£o do pipeline foi feita com a ferramenta **Databricks Jobs**, utilizando m√∫ltiplas tarefas executadas em sequ√™ncia:

1. **Job Bronze** ‚Äì Faz a ingest√£o dos dados.
2. **Job Silver** ‚Äì Executa as valida√ß√µes da camada Silver.
3. **Job Gold** ‚Äì Monta as m√©tricas finais e tabelas de consumo.

Cada job possui depend√™ncias configuradas para garantir a ordem correta da execu√ß√£o.

Al√©m disso, foram implementadas **valida√ß√µes autom√°ticas**, como:

* contagem de registros
* verifica√ß√µes de schema
* checagem de duplicidade
* valida√ß√£o de colunas obrigat√≥rias

## ‚ñ∂Ô∏è Como Executar

Como o projeto **n√£o roda localmente**, a execu√ß√£o ocorre **exclusivamente no Databricks**.

### Passo a passo:

1. Importe o c√≥digo/notebooks para o Workspace do Databricks.
2. Configure os caminhos de leitura e escrita no DBFS.
3. Crie os Jobs no Databricks.
4. Configure as depend√™ncias:

   * Silver depende do Bronze
   * Gold depende do Silver
5. Execute o job principal.

---

## üß™ Valida√ß√µes Implementadas

Durante a evolu√ß√£o das camadas, o pipeline aplica diversas valida√ß√µes:

* Schema validation
* Verifica√ß√£o de nulls
* Duplicidade de chaves
* Normaliza√ß√£o de colunas
* Verifica√ß√£o de consist√™ncia de tipos

Em caso de falha, o job √© interrompido para garantir integridade.
